{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Twitter-Sentiment-Analysis-ML_Model (Soumyadip Majumder)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# installing kaggle library\n",
        "!pip install kaggle"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: kaggle in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (1.6.17)\r\nRequirement already satisfied: tqdm in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from kaggle) (4.66.2)\r\nRequirement already satisfied: certifi>=2023.7.22 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from kaggle) (2024.7.4)\r\nRequirement already satisfied: six>=1.10 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from kaggle) (1.16.0)\r\nRequirement already satisfied: python-slugify in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from kaggle) (8.0.4)\r\nRequirement already satisfied: python-dateutil in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from kaggle) (2.9.0.post0)\r\nRequirement already satisfied: requests in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from kaggle) (2.31.0)\r\nRequirement already satisfied: bleach in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from kaggle) (6.1.0)\r\nRequirement already satisfied: urllib3 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from kaggle) (1.26.18)\r\nRequirement already satisfied: webencodings in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from bleach->kaggle) (0.5.1)\r\nRequirement already satisfied: text-unidecode>=1.3 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from python-slugify->kaggle) (1.3)\r\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from requests->kaggle) (3.7)\r\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from requests->kaggle) (3.3.2)\r\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1724507832846
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# configuring the path of path of Kaggle.json file\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724507835380
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Twitter Sentiment dataset"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# API to fetch the dataset from kaggle\n",
        "!kaggle datasets download -d kazanova/sentiment140"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Dataset URL: https://www.kaggle.com/datasets/kazanova/sentiment140\nLicense(s): other\nDownloading sentiment140.zip to /mnt/batch/tasks/shared/LS_root/mounts/clusters/soumyadipmajumder031/code/Users/soumyadipmajumder03\n 98%|█████████████████████████████████████ | 79.0M/80.9M [00:04<00:00, 26.8MB/s]\n100%|██████████████████████████████████████| 80.9M/80.9M [00:04<00:00, 20.3MB/s]\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724507844592
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing the Dependencies"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn\n",
        "!pip install pandas\n",
        "!pip install nltk"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: scikit-learn in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (1.1.3)\nRequirement already satisfied: joblib>=1.0.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from scikit-learn) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from scikit-learn) (3.4.0)\nRequirement already satisfied: numpy>=1.17.3 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from scikit-learn) (1.23.5)\nRequirement already satisfied: scipy>=1.3.2 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from scikit-learn) (1.5.3)\nRequirement already satisfied: pandas in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (1.3.5)\nRequirement already satisfied: pytz>=2017.3 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from pandas) (2022.5)\nRequirement already satisfied: numpy>=1.17.3 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from pandas) (1.23.5)\nRequirement already satisfied: python-dateutil>=2.7.3 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: six>=1.5 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\nRequirement already satisfied: nltk in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (3.9.1)\nRequirement already satisfied: joblib in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from nltk) (1.2.0)\nRequirement already satisfied: tqdm in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from nltk) (4.66.2)\nRequirement already satisfied: click in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from nltk) (8.1.7)\nRequirement already satisfied: regex>=2021.8.3 in /anaconda/envs/azureml_py38/lib/python3.9/site-packages (from nltk) (2024.4.28)\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724503519354
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Libraries"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724507909290
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# printing the stopwords in English\n",
        "print(stopwords.words('english'))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724507911079
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the data from csv file to pandas dataframe\n",
        "twitter_data = pd.read_csv('training.1600000.processed.noemoticon.csv', encoding='ISO-8859-1')\n",
        "twitter_data.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "   0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY _TheSpecialOne_  \\\n0  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   scotthamilton   \n1  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY        mattycus   \n2  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         ElleCTF   \n3  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          Karoli   \n4  0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY        joy_wolf   \n\n  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n0  is upset that he can't update his Facebook by ...                                                                   \n1  @Kenichan I dived many times for the ball. Man...                                                                   \n2    my whole body feels itchy and like its on fire                                                                    \n3  @nationwideclass no, it's not behaving at all....                                                                   \n4                      @Kwesidei not the whole crew                                                                    ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1467810369</th>\n      <th>Mon Apr 06 22:19:45 PDT 2009</th>\n      <th>NO_QUERY</th>\n      <th>_TheSpecialOne_</th>\n      <th>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1467810672</td>\n      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>scotthamilton</td>\n      <td>is upset that he can't update his Facebook by ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1467810917</td>\n      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>mattycus</td>\n      <td>@Kenichan I dived many times for the ball. Man...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1467811184</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>ElleCTF</td>\n      <td>my whole body feels itchy and like its on fire</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1467811193</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>Karoli</td>\n      <td>@nationwideclass no, it's not behaving at all....</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1467811372</td>\n      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>joy_wolf</td>\n      <td>@Kwesidei not the whole crew</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724507921339
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the number of rows and columns\n",
        "row,col = twitter_data.shape\n",
        "print(\"Rows: \", row)\n",
        "print(\"Columns: \", col)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Rows:  1599999\nColumns:  6\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724507926273
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# naming the columns and reading the dataset again\n",
        "\n",
        "column_names = ['target', 'id', 'date', 'flag', 'user', 'text']\n",
        "twitter_data = pd.read_csv('training.1600000.processed.noemoticon.csv', names=column_names, encoding='ISO-8859-1')\n",
        "twitter_data.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "   target          id                          date      flag  \\\n0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n\n              user                                               text  \n0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n1    scotthamilton  is upset that he can't update his Facebook by ...  \n2         mattycus  @Kenichan I dived many times for the ball. Man...  \n3          ElleCTF    my whole body feels itchy and like its on fire   \n4           Karoli  @nationwideclass no, it's not behaving at all....  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>id</th>\n      <th>date</th>\n      <th>flag</th>\n      <th>user</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1467810369</td>\n      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>_TheSpecialOne_</td>\n      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1467810672</td>\n      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>scotthamilton</td>\n      <td>is upset that he can't update his Facebook by ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1467810917</td>\n      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>mattycus</td>\n      <td>@Kenichan I dived many times for the ball. Man...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1467811184</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>ElleCTF</td>\n      <td>my whole body feels itchy and like its on fire</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1467811193</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>Karoli</td>\n      <td>@nationwideclass no, it's not behaving at all....</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724507937345
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "twitter_data.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "(1600000, 6)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724507945120
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# counting the number of missing values in the dataset\n",
        "twitter_data.isnull().sum()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "target    0\nid        0\ndate      0\nflag      0\nuser      0\ntext      0\ndtype: int64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724507937687
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### From this analysis\n",
        "There is no null value in this dataset."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the distribution of target column\n",
        "twitter_data['target'].value_counts()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "0    800000\n4    800000\nName: target, dtype: int64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724507950671
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From this output, we can say that this dataset contains **16M** tweets extracted using _twitter API_. The tweets have been annotated (0 means negative value and 4 means positive value)\n",
        "\n",
        "##### From the analysis process ('target' column)\n",
        "_total 8M is negative_\n",
        "\n",
        "_total 8M is positive_"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Convert the target \"4\" to \"1\" for good analysis"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "twitter_data.replace({'target':{4:1}}, inplace=True)\n",
        "print(\"Replaced the all values...\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Replaced the all values...\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724507954266
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### After replacing the the all values\n",
        "##### 0 -> Negative Tweet\n",
        "##### 1 -> Positive Tweet"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Stemming is the process to reduce a word to its Root word. It makes for visible and more clear for updated dataset."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### port_stem = PorterStemmer()\n",
        "###### This line initializes an instance of the PorterStemmer class from the nltk library. The Porter Stemmer is a popular algorithm for stemming words, which means reducing words to their root form. For example, “running” becomes “run”."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "port_stem = PorterStemmer()"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724507957973
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### <mark>def stemming(content):</mark>\n",
        "This line defines a function named `stemming` that takes a single argument `content`.\n",
        "\n",
        "\n",
        "`stemmed_content = re.sub('[^a-zA-Z]',' ', content)` --> This line uses the `re` _(regular expression)_ module to substitute any character in `content` that is not a letter (a-z or A-Z) with a space. This helps in removing punctuation, number, and special characters from the text.\n",
        "\n",
        "`streamed content = stemmed_content.split()` --> This line splits the `stemmed_content` string into a list of words. The default delimiter is any white-space.\n",
        "\n",
        "<br><br>\n",
        "`stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')]` --> This line performs several actions:\n",
        "###### 1. List Comprehension:\n",
        "It iterates over each `word` in the `stemmed_content` list.\n",
        "<br>\n",
        "###### 2. Stemming:\n",
        "For each, `word`, it applies the `stem` method of the `PorterStemmer` instance _(port_stem)_ to reduce the word to its root form.\n",
        "<br>\n",
        "###### 3. Stop-words Removal:\n",
        "It includes the word in the final list only if it is not in the list of English stopwords. Stopwords are common words like \"and\", \"the\", \"is\", etc., which are often removed in text processing because they don't carry significant meaning.\n",
        "\n",
        "\n",
        "<br><br>\n",
        "\n",
        "`stemmed_content = ' '.join(stemmed_content)` -->\n",
        "This line joins the list of stemmed words back into a single string, with each word separated by a space.\n",
        "\n",
        "<br>\n",
        "\n",
        "`return stemmed_content` --> simply return the stemmed value.\n",
        "\n",
        "\n",
        "\n",
        "##### Full Function Explanation\n",
        "The `stemming` function takes a text input, removes non-alphabetic characters, converts the text to lowercase, splits it into words, stems each word (excluding stopwords), and then joins the words back into a single string. This processed string is then returned."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stemming(content):\n",
        "    stemmed_content = re.sub('[^a-zA-Z]',' ', content)\n",
        "    stemmed_content = stemmed_content.lower()\n",
        "    stemmed_content = stemmed_content.split()\n",
        "    stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')]\n",
        "    stemmed_content = ' '.join(stemmed_content)\n",
        "\n",
        "    return stemmed_content"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724508059540
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Feature Engineering\n",
        "###### In this dataset there are total of 16 million rows, so after running the `feature engineering` cell block it will take a lot time to execute.\n",
        "###### _Soumyadip Majumder_\n",
        "###### _Kernel: AzureML <mark>(Python 3.8)</mark>_"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# feature engineering\n",
        "# adding new column\n",
        "twitter_data['stemmed_content'] = twitter_data['text'].apply(stemming)"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724509895790
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# checking for updated dataset\n",
        "twitter_data.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 19,
          "data": {
            "text/plain": "   target          id                          date      flag  \\\n0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n\n              user                                               text  \\\n0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n1    scotthamilton  is upset that he can't update his Facebook by ...   \n2         mattycus  @Kenichan I dived many times for the ball. Man...   \n3          ElleCTF    my whole body feels itchy and like its on fire    \n4           Karoli  @nationwideclass no, it's not behaving at all....   \n\n                                     stemmed_content  \n0  switchfoot http twitpic com zl awww bummer sho...  \n1  upset updat facebook text might cri result sch...  \n2  kenichan dive mani time ball manag save rest g...  \n3                    whole bodi feel itchi like fire  \n4                      nationwideclass behav mad see  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>id</th>\n      <th>date</th>\n      <th>flag</th>\n      <th>user</th>\n      <th>text</th>\n      <th>stemmed_content</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1467810369</td>\n      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>_TheSpecialOne_</td>\n      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n      <td>switchfoot http twitpic com zl awww bummer sho...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1467810672</td>\n      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>scotthamilton</td>\n      <td>is upset that he can't update his Facebook by ...</td>\n      <td>upset updat facebook text might cri result sch...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1467810917</td>\n      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>mattycus</td>\n      <td>@Kenichan I dived many times for the ball. Man...</td>\n      <td>kenichan dive mani time ball manag save rest g...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1467811184</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>ElleCTF</td>\n      <td>my whole body feels itchy and like its on fire</td>\n      <td>whole bodi feel itchi like fire</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1467811193</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>Karoli</td>\n      <td>@nationwideclass no, it's not behaving at all....</td>\n      <td>nationwideclass behav mad see</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724510025202
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(twitter_data['stemmed_content'])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "0          switchfoot http twitpic com zl awww bummer sho...\n1          upset updat facebook text might cri result sch...\n2          kenichan dive mani time ball manag save rest g...\n3                            whole bodi feel itchi like fire\n4                              nationwideclass behav mad see\n                                 ...                        \n1599995                           woke school best feel ever\n1599996    thewdb com cool hear old walt interview http b...\n1599997                         readi mojo makeov ask detail\n1599998    happi th birthday boo alll time tupac amaru sh...\n1599999    happi charitytuesday thenspcc sparkschar speak...\nName: stemmed_content, Length: 1600000, dtype: object\n"
        }
      ],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724510077818
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(twitter_data['target'])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "0          0\n1          0\n2          0\n3          0\n4          0\n          ..\n1599995    1\n1599996    1\n1599997    1\n1599998    1\n1599999    1\nName: target, Length: 1600000, dtype: int64\n"
        }
      ],
      "execution_count": 21,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724510101720
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# separating the data and label\n",
        "X = twitter_data['stemmed_content'].values\n",
        "y = twitter_data['target'].values"
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724510239180
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X: \", X)\n",
        "print(\"y: \", y)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "X:  ['switchfoot http twitpic com zl awww bummer shoulda got david carr third day'\n 'upset updat facebook text might cri result school today also blah'\n 'kenichan dive mani time ball manag save rest go bound' ...\n 'readi mojo makeov ask detail'\n 'happi th birthday boo alll time tupac amaru shakur'\n 'happi charitytuesday thenspcc sparkschar speakinguph h']\ny:  [0 0 0 ... 1 1 1]\n"
        }
      ],
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724510250862
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split the data for training and test the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=2)"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724510426605
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X.shape: \", X.shape)\n",
        "print(\"X_train.shape: \", X_train.shape)\n",
        "print(\"X_test.shape: \", X_test.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "X.shape:  (1600000,)\nX_train.shape:  (1280000,)\nX_test.shape:  (320000,)\n"
        }
      ],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724510694120
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "['watch saw iv drink lil wine' 'hatermagazin'\n 'even though favourit drink think vodka coke wipe mind time think im gonna find new drink'\n ... 'eager monday afternoon'\n 'hope everyon mother great day wait hear guy store tomorrow'\n 'love wake folger bad voic deeper']\n"
        }
      ],
      "execution_count": 26,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724510710398
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "['mmangen fine much time chat twitter hubbi back summer amp tend domin free time'\n 'ah may show w ruth kim amp geoffrey sanhueza'\n 'ishatara mayb bay area thang dammit' ...\n 'destini nevertheless hooray member wonder safe trip' 'feel well'\n 'supersandro thank']\n"
        }
      ],
      "execution_count": 27,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724510715788
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Converting the textual data to numerical data"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# converting text to numerical data\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "X_train = vectorizer.fit_transform(X_train)\n",
        "X_test = vectorizer.transform(X_test)"
      ],
      "outputs": [],
      "execution_count": 28,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724510854449
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "  (0, 443066)\t0.4484755317023172\n  (0, 235045)\t0.41996827700291095\n  (0, 109306)\t0.3753708587402299\n  (0, 185193)\t0.5277679060576009\n  (0, 354543)\t0.3588091611460021\n  (0, 436713)\t0.2725987626483838\n  (1, 160636)\t1.0\n  (2, 288470)\t0.16786949597862733\n  (2, 132311)\t0.20289715703997938\n  (2, 150715)\t0.18803850583207948\n  (2, 178061)\t0.1619010109445149\n  (2, 409143)\t0.15169282335109835\n  (2, 266729)\t0.24123230668976975\n  (2, 443430)\t0.3348599670252845\n  (2, 77929)\t0.31284080750346344\n  (2, 433560)\t0.3296595898028565\n  (2, 406399)\t0.32105459490875526\n  (2, 129411)\t0.29074192727957143\n  (2, 407301)\t0.1870933868497303\n  (2, 124484)\t0.1892155960801415\n  (2, 109306)\t0.4591176413728317\n  (3, 172421)\t0.37464146922154384\n  (3, 411528)\t0.27089772444087873\n  (3, 388626)\t0.3940776331458846\n  (3, 56476)\t0.5200465453608686\n  :\t:\n  (1279996, 390130)\t0.2206474219107611\n  (1279996, 434014)\t0.2718945052332447\n  (1279996, 318303)\t0.21254698865277746\n  (1279996, 237899)\t0.22365675600992338\n  (1279996, 291078)\t0.17981734369155505\n  (1279996, 412553)\t0.18967045002348676\n  (1279997, 112591)\t0.7574829183045267\n  (1279997, 273084)\t0.4353549002982409\n  (1279997, 5685)\t0.486503586074313\n  (1279998, 385313)\t0.41032858655881904\n  (1279998, 275288)\t0.38703346602729577\n  (1279998, 162047)\t0.3469172695815906\n  (1279998, 156297)\t0.3137096161546449\n  (1279998, 153281)\t0.28378968751027456\n  (1279998, 435463)\t0.2851807874350361\n  (1279998, 124765)\t0.32241752985927996\n  (1279998, 169461)\t0.2659980990397061\n  (1279998, 93795)\t0.21717768937055476\n  (1279998, 412553)\t0.2816582375021589\n  (1279999, 96224)\t0.5416162421321443\n  (1279999, 135384)\t0.6130934129868719\n  (1279999, 433612)\t0.3607341026233411\n  (1279999, 435572)\t0.31691096877786484\n  (1279999, 31410)\t0.248792678366695\n  (1279999, 242268)\t0.19572649660865402\n"
        }
      ],
      "execution_count": 29,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724510868261
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "  (0, 420984)\t0.17915624523539803\n  (0, 409143)\t0.31430470598079707\n  (0, 398906)\t0.3491043873264266\n  (0, 388348)\t0.21985076072061732\n  (0, 279082)\t0.1782518010910344\n  (0, 271016)\t0.4535662391658828\n  (0, 171378)\t0.2805816206356073\n  (0, 138164)\t0.23688292264071403\n  (0, 132364)\t0.25525488955578596\n  (0, 106069)\t0.3655545001090455\n  (0, 67828)\t0.2680037527082731\n  (0, 31168)\t0.16247724180521766\n  (0, 15110)\t0.1719352837797837\n  (1, 366203)\t0.24595562404108307\n  (1, 348135)\t0.4739279595416274\n  (1, 256777)\t0.28751585696559306\n  (1, 217562)\t0.40288153995289894\n  (1, 145393)\t0.575262969264869\n  (1, 15110)\t0.211037449588008\n  (1, 6463)\t0.30733520460524466\n  (2, 400621)\t0.4317732461913093\n  (2, 256834)\t0.2564939661498775\n  (2, 183312)\t0.5892069252021465\n  (2, 89448)\t0.36340369428387626\n  (2, 34401)\t0.37916255084357414\n  :\t:\n  (319994, 123278)\t0.45303413825598426\n  (319995, 444934)\t0.3211092817599261\n  (319995, 420984)\t0.22631428606830145\n  (319995, 416257)\t0.23816465111736276\n  (319995, 324496)\t0.3613167933647574\n  (319995, 315813)\t0.28482299145634127\n  (319995, 296662)\t0.39924856793840147\n  (319995, 232891)\t0.25741278545890767\n  (319995, 213324)\t0.2683969144317078\n  (319995, 155493)\t0.2770682832971668\n  (319995, 109379)\t0.30208964848908326\n  (319995, 107868)\t0.3339934973754696\n  (319996, 438709)\t0.4143006291901984\n  (319996, 397506)\t0.9101400928717545\n  (319997, 444770)\t0.2668297951055569\n  (319997, 416695)\t0.29458327588067873\n  (319997, 349904)\t0.32484594100566083\n  (319997, 288421)\t0.48498483387153407\n  (319997, 261286)\t0.37323893626855326\n  (319997, 169411)\t0.403381646999604\n  (319997, 98792)\t0.4463892055808332\n  (319998, 438748)\t0.719789181620468\n  (319998, 130192)\t0.6941927210956169\n  (319999, 400636)\t0.2874420848216212\n  (319999, 389755)\t0.9577980203954276\n"
        }
      ],
      "execution_count": 30,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724510875189
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training the Machine Learning Model\n",
        "##### Logistic Regression"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(max_iter=1000)"
      ],
      "outputs": [],
      "execution_count": 32,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724511328188
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 33,
          "data": {
            "text/plain": "LogisticRegression(max_iter=1000)",
            "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 33,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724511404442
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model Evaluation\n",
        "##### Accuracy score"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy score on the trainning data\n",
        "\n",
        "X_train_prediction = model.predict(X_train)\n",
        "training_data_accuracy = accuracy_score(y_train, X_train_prediction)"
      ],
      "outputs": [],
      "execution_count": 35,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724511589670
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy score on the training data: ', training_data_accuracy)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Accuracy score on the training data:  0.81023671875\n"
        }
      ],
      "execution_count": 36,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724511608207
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy in percentage: {:.2f}%'.format(training_data_accuracy*100))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Accuracy in percentage: 81.02%\n"
        }
      ],
      "execution_count": 39,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724511805363
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy score on test data\n",
        "X_test_prediction = model.predict(X_test)\n",
        "test_data_accuracy = accuracy_score(y_test, X_test_prediction)"
      ],
      "outputs": [],
      "execution_count": 40,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724511884481
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For better visualisation I've created a custom formatted display\n",
        "\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "def display_markdown_test_dataOutput(output):\n",
        "    display(Markdown(output))\n",
        "\n",
        "formatted_test_data_accuracy = f\"**Test data accuracy: {test_data_accuracy*100:.2f}%**\"\n",
        "display_markdown_test_dataOutput(formatted_test_data_accuracy)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "**Test data accuracy: 77.80%**"
          },
          "metadata": {}
        }
      ],
      "execution_count": 51,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724512309212
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Saving the trained model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "outputs": [],
      "execution_count": 52,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724512356140
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'trained_model.pkl'\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ],
      "outputs": [],
      "execution_count": 53,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724512608824
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Using the saved model for future predictions"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the saved model\n",
        "loaded_model = pickle.load(open('trained_model.pkl', 'rb'))   # 'rb': Read in Binary format"
      ],
      "outputs": [],
      "execution_count": 54,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724512746629
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_new = X_test[200]\n",
        "print(y_test[200])\n",
        "\n",
        "new_prediction = model.predict(X_new)\n",
        "print(new_prediction)\n",
        "\n",
        "if (new_prediction[0] == 0):\n",
        "    print('Negative Tweet')\n",
        "else:\n",
        "    print('Positive Tweet')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "1\n[1]\nPositive Tweet\n"
        }
      ],
      "execution_count": 57,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724514036043
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Complete AzureML-Tweet-Sentiment-Analysis\n",
        "\n",
        "**Soumyadip Majumder**\n",
        "\n",
        "**Kernel: AzureML (Python3.8)**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "run_control": {
          "frozen": false
        },
        "editable": false
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.19",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}